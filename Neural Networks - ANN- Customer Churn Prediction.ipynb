{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Artificial Neutral Network Customer Churn Prediction", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "#Installing Theano, Tensorflow, Keras", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "source": "import keras"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 9, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowNumber</th>\n      <th>CustomerId</th>\n      <th>Surname</th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>15634602</td>\n      <td>Hargrave</td>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>15647311</td>\n      <td>Hill</td>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>15619304</td>\n      <td>Onio</td>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>15701354</td>\n      <td>Boni</td>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>15737888</td>\n      <td>Mitchell</td>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n0          1    15634602  Hargrave          619    France  Female   42   \n1          2    15647311      Hill          608     Spain  Female   41   \n2          3    15619304      Onio          502    France  Female   42   \n3          4    15701354      Boni          699    France  Female   39   \n4          5    15737888  Mitchell          850     Spain  Female   43   \n\n   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n0       2       0.00              1          1               1   \n1       1   83807.86              1          0               1   \n2       8  159660.80              3          1               0   \n3       1       0.00              2          0               0   \n4       2  125510.82              1          1               1   \n\n   EstimatedSalary  Exited  \n0        101348.88       1  \n1        112542.58       0  \n2        113931.57       1  \n3         93826.63       0  \n4         79084.10       0  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np"
        }, 
        {
            "execution_count": 69, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "X=df_data_1.iloc[:,3:13].values"
        }, 
        {
            "execution_count": 70, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y=df_data_1.iloc[:,13].values"
        }, 
        {
            "source": "#Encoding Categorical data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 71, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder_X_1 = LabelEncoder()\nX[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\nlabelencoder_X_2 = LabelEncoder()\nX[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n"
        }, 
        {
            "execution_count": 72, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 72, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[619, 0, 0, ..., 1, 1, 101348.88],\n       [608, 2, 0, ..., 0, 1, 112542.58],\n       [502, 0, 0, ..., 1, 0, 113931.57],\n       ..., \n       [709, 0, 0, ..., 0, 1, 42085.58],\n       [772, 1, 1, ..., 1, 0, 92888.52],\n       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "X"
        }, 
        {
            "execution_count": 73, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Create dummy variables\nonehotencoder = OneHotEncoder(categorical_features = [1])\nX = onehotencoder.fit_transform(X).toarray()\nX = X[:, 1:]"
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 22, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[  0.00000000e+00,   1.00000000e+00,   0.00000000e+00, ...,\n          1.00000000e+00,   1.00000000e+00,   1.01348880e+05],\n       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n          0.00000000e+00,   1.00000000e+00,   1.12542580e+05],\n       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00, ...,\n          1.00000000e+00,   0.00000000e+00,   1.13931570e+05],\n       ..., \n       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00, ...,\n          0.00000000e+00,   1.00000000e+00,   4.20855800e+04],\n       [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00, ...,\n          1.00000000e+00,   0.00000000e+00,   9.28885200e+04],\n       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00, ...,\n          1.00000000e+00,   0.00000000e+00,   3.81907800e+04]])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "X\n"
        }, 
        {
            "execution_count": 74, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Splitting training and test dataset\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
        }, 
        {
            "execution_count": 75, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)"
        }, 
        {
            "execution_count": 76, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from keras.models import Sequential\nfrom keras.layers import Dense"
        }, 
        {
            "execution_count": 77, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#initializing classfier\nclassifier =Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n"
        }, 
        {
            "execution_count": 78, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 78, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(10000, 11)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "X.shape"
        }, 
        {
            "execution_count": 79, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 79, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(8000, 11)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "X_train.shape"
        }, 
        {
            "execution_count": 80, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ipykernel/__main__.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", input_dim=11, units=6, activation=\"relu\")`\n  if __name__ == '__main__':\n"
                }
            ], 
            "source": "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n"
        }, 
        {
            "execution_count": 41, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import pip"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!pip install --upgrade keras"
        }, 
        {
            "execution_count": 81, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", units=6, activation=\"relu\")`\n"
                }
            ], 
            "source": "#Add second hidden layer\nfrom ipykernel import kernelapp as app\n\nclassifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n"
        }, 
        {
            "execution_count": 86, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", units=1, activation=\"sigmoid\")`\n  from ipykernel import kernelapp as app\n"
                }
            ], 
            "source": "#Add Output layer\nclassifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n\n"
        }, 
        {
            "execution_count": 87, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
        }, 
        {
            "execution_count": 88, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Epoch 1/100\n8000/8000 [==============================] - 6s 746us/step - loss: 0.5076 - acc: 0.7960\nEpoch 2/100\n8000/8000 [==============================] - 6s 735us/step - loss: 0.4547 - acc: 0.7960\nEpoch 3/100\n8000/8000 [==============================] - 6s 726us/step - loss: 0.4437 - acc: 0.7960\nEpoch 4/100\n8000/8000 [==============================] - 6s 714us/step - loss: 0.4354 - acc: 0.7960\nEpoch 5/100\n8000/8000 [==============================] - 6s 724us/step - loss: 0.4288 - acc: 0.7960\nEpoch 6/100\n8000/8000 [==============================] - 6s 749us/step - loss: 0.4242 - acc: 0.7960\nEpoch 7/100\n8000/8000 [==============================] - 6s 726us/step - loss: 0.4208 - acc: 0.7960\nEpoch 8/100\n8000/8000 [==============================] - 6s 713us/step - loss: 0.4176 - acc: 0.8004\nEpoch 9/100\n8000/8000 [==============================] - 6s 713us/step - loss: 0.4157 - acc: 0.8296\nEpoch 10/100\n8000/8000 [==============================] - 6s 726us/step - loss: 0.4140 - acc: 0.8312\nEpoch 11/100\n8000/8000 [==============================] - 6s 712us/step - loss: 0.4116 - acc: 0.8304\nEpoch 12/100\n8000/8000 [==============================] - 6s 713us/step - loss: 0.4107 - acc: 0.8314\nEpoch 13/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.4092 - acc: 0.8301\nEpoch 14/100\n8000/8000 [==============================] - 6s 713us/step - loss: 0.4081 - acc: 0.8312\nEpoch 15/100\n8000/8000 [==============================] - 6s 726us/step - loss: 0.4075 - acc: 0.8332\nEpoch 16/100\n8000/8000 [==============================] - 6s 722us/step - loss: 0.4069 - acc: 0.8331\nEpoch 17/100\n8000/8000 [==============================] - 6s 726us/step - loss: 0.4065 - acc: 0.8337\nEpoch 18/100\n8000/8000 [==============================] - 6s 724us/step - loss: 0.4060 - acc: 0.8335\nEpoch 19/100\n8000/8000 [==============================] - 6s 702us/step - loss: 0.4054 - acc: 0.8335\nEpoch 20/100\n8000/8000 [==============================] - 6s 714us/step - loss: 0.4045 - acc: 0.8351\nEpoch 21/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.4040 - acc: 0.8337\nEpoch 22/100\n8000/8000 [==============================] - 6s 724us/step - loss: 0.4035 - acc: 0.8342\nEpoch 23/100\n8000/8000 [==============================] - 6s 702us/step - loss: 0.4032 - acc: 0.8330\nEpoch 24/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.4026 - acc: 0.8344\nEpoch 25/100\n8000/8000 [==============================] - 6s 736us/step - loss: 0.4023 - acc: 0.8350\nEpoch 26/100\n8000/8000 [==============================] - 6s 724us/step - loss: 0.4015 - acc: 0.8330\nEpoch 27/100\n8000/8000 [==============================] - 6s 738us/step - loss: 0.4020 - acc: 0.8340\nEpoch 28/100\n8000/8000 [==============================] - 6s 737us/step - loss: 0.4014 - acc: 0.8335\nEpoch 29/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.4008 - acc: 0.8342\nEpoch 30/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.4009 - acc: 0.8340\nEpoch 31/100\n8000/8000 [==============================] - 6s 714us/step - loss: 0.4003 - acc: 0.8345\nEpoch 32/100\n8000/8000 [==============================] - 6s 736us/step - loss: 0.3998 - acc: 0.8360\nEpoch 33/100\n8000/8000 [==============================] - 6s 726us/step - loss: 0.4000 - acc: 0.8356\nEpoch 34/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.4000 - acc: 0.8350\nEpoch 35/100\n8000/8000 [==============================] - 6s 714us/step - loss: 0.3999 - acc: 0.8339\nEpoch 36/100\n8000/8000 [==============================] - 6s 748us/step - loss: 0.3991 - acc: 0.8347\nEpoch 37/100\n8000/8000 [==============================] - 6s 724us/step - loss: 0.3992 - acc: 0.8372\nEpoch 38/100\n8000/8000 [==============================] - 6s 738us/step - loss: 0.3988 - acc: 0.8375\nEpoch 39/100\n8000/8000 [==============================] - 6s 739us/step - loss: 0.3987 - acc: 0.8354\nEpoch 40/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.3983 - acc: 0.8362\nEpoch 41/100\n8000/8000 [==============================] - 6s 738us/step - loss: 0.3986 - acc: 0.8346\nEpoch 42/100\n8000/8000 [==============================] - 6s 713us/step - loss: 0.3980 - acc: 0.8364\nEpoch 43/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.3981 - acc: 0.8337\nEpoch 44/100\n8000/8000 [==============================] - 6s 723us/step - loss: 0.3982 - acc: 0.8359\nEpoch 45/100\n8000/8000 [==============================] - 6s 724us/step - loss: 0.3979 - acc: 0.8362\nEpoch 46/100\n8000/8000 [==============================] - 6s 713us/step - loss: 0.3976 - acc: 0.8356\nEpoch 47/100\n8000/8000 [==============================] - 6s 737us/step - loss: 0.3967 - acc: 0.8351 2s - l\nEpoch 48/100\n8000/8000 [==============================] - 6s 739us/step - loss: 0.3973 - acc: 0.8367\nEpoch 49/100\n8000/8000 [==============================] - 6s 737us/step - loss: 0.3973 - acc: 0.8372\nEpoch 50/100\n8000/8000 [==============================] - 6s 736us/step - loss: 0.3971 - acc: 0.8374\nEpoch 51/100\n8000/8000 [==============================] - 6s 713us/step - loss: 0.3974 - acc: 0.8366\nEpoch 52/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.3966 - acc: 0.8359\nEpoch 53/100\n8000/8000 [==============================] - 6s 724us/step - loss: 0.3971 - acc: 0.8367\nEpoch 54/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.3965 - acc: 0.8379\nEpoch 55/100\n8000/8000 [==============================] - 6s 714us/step - loss: 0.3966 - acc: 0.8382\nEpoch 56/100\n8000/8000 [==============================] - 6s 712us/step - loss: 0.3966 - acc: 0.8374\nEpoch 57/100\n8000/8000 [==============================] - 6s 737us/step - loss: 0.3967 - acc: 0.8375\nEpoch 58/100\n8000/8000 [==============================] - 6s 712us/step - loss: 0.3964 - acc: 0.8364\nEpoch 59/100\n8000/8000 [==============================] - 6s 736us/step - loss: 0.3965 - acc: 0.8377\nEpoch 60/100\n8000/8000 [==============================] - 6s 727us/step - loss: 0.3960 - acc: 0.8394\nEpoch 61/100\n8000/8000 [==============================] - 6s 736us/step - loss: 0.3959 - acc: 0.8371 1s - loss: 0.\nEpoch 62/100\n8000/8000 [==============================] - 6s 712us/step - loss: 0.3960 - acc: 0.8374\nEpoch 63/100\n8000/8000 [==============================] - 6s 713us/step - loss: 0.3956 - acc: 0.8369\nEpoch 64/100\n8000/8000 [==============================] - 6s 713us/step - loss: 0.3959 - acc: 0.8394\nEpoch 65/100\n8000/8000 [==============================] - 6s 723us/step - loss: 0.3958 - acc: 0.8370\nEpoch 66/100\n8000/8000 [==============================] - 6s 713us/step - loss: 0.3957 - acc: 0.8376\nEpoch 67/100\n8000/8000 [==============================] - 6s 713us/step - loss: 0.3954 - acc: 0.8397 1s - loss: 0.4027 -\nEpoch 68/100\n8000/8000 [==============================] - 6s 726us/step - loss: 0.3955 - acc: 0.8377\nEpoch 69/100\n8000/8000 [==============================] - 6s 724us/step - loss: 0.3957 - acc: 0.8380\nEpoch 70/100\n8000/8000 [==============================] - 6s 736us/step - loss: 0.3952 - acc: 0.8386\nEpoch 71/100\n8000/8000 [==============================] - 6s 738us/step - loss: 0.3952 - acc: 0.8385\nEpoch 72/100\n8000/8000 [==============================] - 6s 727us/step - loss: 0.3952 - acc: 0.8382\nEpoch 73/100\n8000/8000 [==============================] - 6s 715us/step - loss: 0.3950 - acc: 0.8369\nEpoch 74/100\n8000/8000 [==============================] - 6s 701us/step - loss: 0.3952 - acc: 0.8379\nEpoch 75/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.3945 - acc: 0.8374\nEpoch 76/100\n8000/8000 [==============================] - 6s 726us/step - loss: 0.3952 - acc: 0.8374\nEpoch 77/100\n8000/8000 [==============================] - 6s 723us/step - loss: 0.3949 - acc: 0.8407\nEpoch 78/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.3949 - acc: 0.8366\nEpoch 79/100\n8000/8000 [==============================] - 6s 724us/step - loss: 0.3947 - acc: 0.8375\nEpoch 80/100\n8000/8000 [==============================] - 6s 713us/step - loss: 0.3946 - acc: 0.8384\nEpoch 81/100\n8000/8000 [==============================] - 6s 724us/step - loss: 0.3949 - acc: 0.8386\nEpoch 82/100\n8000/8000 [==============================] - 6s 737us/step - loss: 0.3948 - acc: 0.8389 1s - loss: 0.391\nEpoch 83/100\n8000/8000 [==============================] - 6s 726us/step - loss: 0.3945 - acc: 0.8392\nEpoch 84/100\n8000/8000 [==============================] - 6s 712us/step - loss: 0.3948 - acc: 0.8395\nEpoch 85/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.3946 - acc: 0.8389\nEpoch 86/100\n8000/8000 [==============================] - 6s 712us/step - loss: 0.3946 - acc: 0.8379\nEpoch 87/100\n8000/8000 [==============================] - 6s 712us/step - loss: 0.3945 - acc: 0.8390\nEpoch 88/100\n8000/8000 [==============================] - 6s 712us/step - loss: 0.3944 - acc: 0.8404\nEpoch 89/100\n8000/8000 [==============================] - 6s 727us/step - loss: 0.3944 - acc: 0.8391\nEpoch 90/100\n8000/8000 [==============================] - 6s 738us/step - loss: 0.3943 - acc: 0.8392\nEpoch 91/100\n8000/8000 [==============================] - 6s 726us/step - loss: 0.3944 - acc: 0.8385\nEpoch 92/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.3939 - acc: 0.8390\nEpoch 93/100\n8000/8000 [==============================] - 6s 726us/step - loss: 0.3946 - acc: 0.8382\nEpoch 94/100\n8000/8000 [==============================] - 6s 724us/step - loss: 0.3945 - acc: 0.8396\nEpoch 95/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.3940 - acc: 0.8370\nEpoch 96/100\n8000/8000 [==============================] - 6s 725us/step - loss: 0.3938 - acc: 0.8410\nEpoch 97/100\n8000/8000 [==============================] - 6s 726us/step - loss: 0.3941 - acc: 0.8390\nEpoch 98/100\n8000/8000 [==============================] - 6s 724us/step - loss: 0.3940 - acc: 0.8391\nEpoch 99/100\n8000/8000 [==============================] - 6s 714us/step - loss: 0.3941 - acc: 0.8395\nEpoch 100/100\n8000/8000 [==============================] - 6s 735us/step - loss: 0.3940 - acc: 0.8394\n"
                }, 
                {
                    "execution_count": 88, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x2ad6aa5c51d0>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# Fitting the ANN to the Training set\nclassifier.fit(X_train, y_train, batch_size = 10, epochs = 100)\n"
        }, 
        {
            "execution_count": 95, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)"
        }, 
        {
            "execution_count": 96, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)"
        }, 
        {
            "execution_count": 97, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 97, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[1554,   41],\n       [ 269,  136]])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "cm"
        }, 
        {
            "execution_count": 92, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 92, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[False],\n       [False],\n       [False],\n       ..., \n       [False],\n       [False],\n       [False]], dtype=bool)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "y_pred"
        }, 
        {
            "execution_count": 93, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y_pred = classifier.predict(X_test)\n"
        }, 
        {
            "execution_count": 94, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 94, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[ 0.16240008],\n       [ 0.33329418],\n       [ 0.14915329],\n       ..., \n       [ 0.10266108],\n       [ 0.15848713],\n       [ 0.14016064]], dtype=float32)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "y_pred"
        }, 
        {
            "execution_count": 98, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "accuracy=(1554+136)/2000"
        }, 
        {
            "execution_count": 99, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 99, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.845"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "accuracy"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}